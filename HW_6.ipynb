{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "HW 7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmlB8kD_6uhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"ensembles\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ws-YfSp6uh3",
        "colab_type": "text"
      },
      "source": [
        "Prepare the data. Load breast cancer data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fABL-sga6uh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "bf8d6c55-78f6-4a7d-f11d-d62a8fce28f8"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()\n",
        "print(cancer.target[0:20])\n",
        "print(list(cancer.target_names))\n",
        "print(cancer.data[0:5])\n",
        "print(list(cancer.feature_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "['malignant', 'benign']\n",
            "[[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
            "  1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
            "  6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
            "  1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
            "  4.601e-01 1.189e-01]\n",
            " [2.057e+01 1.777e+01 1.329e+02 1.326e+03 8.474e-02 7.864e-02 8.690e-02\n",
            "  7.017e-02 1.812e-01 5.667e-02 5.435e-01 7.339e-01 3.398e+00 7.408e+01\n",
            "  5.225e-03 1.308e-02 1.860e-02 1.340e-02 1.389e-02 3.532e-03 2.499e+01\n",
            "  2.341e+01 1.588e+02 1.956e+03 1.238e-01 1.866e-01 2.416e-01 1.860e-01\n",
            "  2.750e-01 8.902e-02]\n",
            " [1.969e+01 2.125e+01 1.300e+02 1.203e+03 1.096e-01 1.599e-01 1.974e-01\n",
            "  1.279e-01 2.069e-01 5.999e-02 7.456e-01 7.869e-01 4.585e+00 9.403e+01\n",
            "  6.150e-03 4.006e-02 3.832e-02 2.058e-02 2.250e-02 4.571e-03 2.357e+01\n",
            "  2.553e+01 1.525e+02 1.709e+03 1.444e-01 4.245e-01 4.504e-01 2.430e-01\n",
            "  3.613e-01 8.758e-02]\n",
            " [1.142e+01 2.038e+01 7.758e+01 3.861e+02 1.425e-01 2.839e-01 2.414e-01\n",
            "  1.052e-01 2.597e-01 9.744e-02 4.956e-01 1.156e+00 3.445e+00 2.723e+01\n",
            "  9.110e-03 7.458e-02 5.661e-02 1.867e-02 5.963e-02 9.208e-03 1.491e+01\n",
            "  2.650e+01 9.887e+01 5.677e+02 2.098e-01 8.663e-01 6.869e-01 2.575e-01\n",
            "  6.638e-01 1.730e-01]\n",
            " [2.029e+01 1.434e+01 1.351e+02 1.297e+03 1.003e-01 1.328e-01 1.980e-01\n",
            "  1.043e-01 1.809e-01 5.883e-02 7.572e-01 7.813e-01 5.438e+00 9.444e+01\n",
            "  1.149e-02 2.461e-02 5.688e-02 1.885e-02 1.756e-02 5.115e-03 2.254e+01\n",
            "  1.667e+01 1.522e+02 1.575e+03 1.374e-01 2.050e-01 4.000e-01 1.625e-01\n",
            "  2.364e-01 7.678e-02]]\n",
            "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wovdj046uh8",
        "colab_type": "text"
      },
      "source": [
        "# Problem 1. \n",
        "Break the data into training (80%)/testing data(20%). Estimate a tree classification model with maximum depth of 2. Plot the tree and calculate the accuracy rate. Predict target using all features, don't forget to set random numbers to 42. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N51zg8P6uh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Starting point\n",
        "import random\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "import pydotplus\n",
        "X = cancer.data \n",
        "y = cancer.target\n",
        "random.seed(42)\n",
        "import os     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM3WTVpe6uh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSd5tPtJ6uiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45NAj3FO7w7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVDoHBpB6uiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2cajR426uiJ",
        "colab_type": "text"
      },
      "source": [
        "Problem 2: \n",
        "Estimate an unrestricted tree on training data and test it on testing data. Find two most important features and create a scatter plot of malignant and benign tumors along the two axes of two most important feature. Hint: For example of a graph look at:\n",
        "https://stackoverflow.com/questions/12487060/matplotlib-color-according-to-class-labels\n",
        "Do you think the data need rotation?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrTEMjjf6uiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RJwYbVN6uiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEwvXRB-6uiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV0EpxQr6uiR",
        "colab_type": "text"
      },
      "source": [
        "# Problem 3\n",
        "\n",
        "Report accuracy using top 2 features on the full data from problem 2. Loop over 10000 random number between -1 and 1 (from -3 to 3 radians) to find an optimal rotation angle. Report accuracy improvelemt over unrotated data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuzP_T_i6uiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzJAw5Jo6uiU",
        "colab_type": "text"
      },
      "source": [
        " # Problem 4\n",
        "In the main data drop variables used in the problem 3. Add instead the rotated variables (substitution). \n",
        "Estimate accuracy score using with a tree classifier with max depth = 2 (Same as in problem 1).  How much did we gain from rotation?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgf1B2F-6uiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ozr4HSv6uiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1vyoW106uiY",
        "colab_type": "text"
      },
      "source": [
        "# Problem 5\n",
        "Generate samples of 100,  10,000 and  100,000, moons using the code below. Set random seed at 42. Split data in training and testing sets. Estimate separately Logistic, Random Forest, SVC and the hard voting classifier. What happens to the accuracy score as you increase the number of observations?  Measyre and report the time it takes for each estimation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NtFPJnj6uiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNqcBWgB6uia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR0dkCgH6uic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PL5kU0c6uie",
        "colab_type": "text"
      },
      "source": [
        "Answer: As we increase the number of observations the quality of prediction using Logistic goes down, which SVC takes the lead. SVC though is very slow. Though generally Voting classifier performs better it is inferior to SVC with the large number of data points. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYciDO2M6uie",
        "colab_type": "text"
      },
      "source": [
        "# Problem 6\n",
        "Generate data using the code provided below. Using testing accuracy as metric, estimate bagging random trees estimator with 200 estimators. Try different numbers of samples: 10, 30, 50, and 200. What is optimal number of samples to be used? <br>\n",
        "BaggingClassifier(\n",
        "    DecisionTreeClassifier(random_state=42), n_estimators=5,\n",
        "    max_samples= ?, bootstrap=True, n_jobs=-1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooB7zQ5n6uie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = make_moons(n_samples=500, noise=0.40, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1QtrdPg6uig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwXPndeq6uii",
        "colab_type": "text"
      },
      "source": [
        "# Problem 7\n",
        "Find optimal learning rate, number of estimators and maximum depth using GradientBoostingClassifier, and Randomize grid search. Set a grid: learning rate from 0.01 to 3, number of estimators from 1 to 20, and maximum depth from 1 to 10. Try 300 iterations. Example for randomizeSearch:\n",
        "\n",
        "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
        "                                n_iter=?, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
        "gbrt = GradientBoostingClassifier(max_depth=?, n_estimators=?, learning_rate = ?, random_state=42)  \n",
        "\n",
        "Which estimator was the best? What was the accuracy of the best estimator?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrPaJYJh6uii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = make_moons(n_samples=2000, noise=0.40, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G339QG_U6uik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jih-wiEA6uim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}